{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning technique on PET block detector development - Part 2-4\n",
    "\n",
    "## Crystal/Pixel discrimination for DQS PET block detector using Machine Learning techniques (v1.0, 2019-09)   \n",
    "## (Continued from Part 2-3)\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  \n",
    "### 8. Scintillator/Pixel discrimination using ML algorithms - Part IV, using Neuro Network algorithm\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load libraries\n",
    "\n",
    "import uproot\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "# %matplotlib qt\n",
    "%matplotlib inline\n",
    "# %matplotlib notebook\n",
    "\n",
    "import pickle\n",
    "from sklearn.externals import joblib\n",
    "from sklearn import metrics\n",
    "import time\n",
    "\n",
    "plt.rcParams['figure.dpi'] = 120 # default is 72"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# re-load data\n",
    "\n",
    "file = \"D:\\\\ML on PET block\\\\new_concept_block_lso\\\\new_concept_block_15x15\\\\results\\\\ML_data\\\\new_concept_block_15x15_sorted_events1.csv\"\n",
    "df0 = pd.read_csv (file, comment='#')\n",
    "\n",
    "X = df0.iloc[:,4:].values\n",
    "decoding = df0.iloc[:,0:4].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "infile = open('./pickle/temp_data1','rb')\n",
    "X_t, X_b, X_a, X_g, X_c, index_train, index_test = pickle.load(infile)\n",
    "infile.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pixel_xy = np.array(df0['index_y'] * 15 + df0['index_x'])\n",
    "pixel_x = np.array(df0['index_x'])\n",
    "pixel_y = np.array(df0['index_y'])\n",
    "pixel_xy = pixel_y * 15 + pixel_x\n",
    "\n",
    "pixel_x_train = pixel_x[index_train]\n",
    "pixel_y_train = pixel_y[index_train]\n",
    "pixel_xy_train = pixel_xy[index_train]\n",
    "\n",
    "pixel_x_test = pixel_x[index_test]\n",
    "pixel_y_test = pixel_y[index_test]\n",
    "pixel_xy_test = pixel_xy[index_test]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import check_random_state\n",
    "\n",
    "def random_cmap(ncolors=256, random_state=None):\n",
    "    \"\"\"\n",
    "    Generate a matplotlib colormap consisting of random (muted) colors.\n",
    "\n",
    "    A random colormap is very useful for plotting segmentation images.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    ncolors : int, optional\n",
    "        The number of colors in the colormap.  The default is 256.\n",
    "\n",
    "    random_state : int or `~numpy.random.RandomState`, optional\n",
    "        The pseudo-random number generator state used for random\n",
    "        sampling.  Separate function calls with the same\n",
    "        ``random_state`` will generate the same colormap.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    cmap : `matplotlib.colors.Colormap`\n",
    "        The matplotlib colormap with random colors.\n",
    "    \"\"\"\n",
    "\n",
    "    from matplotlib import colors\n",
    "\n",
    "    prng = check_random_state(random_state)\n",
    "    h = prng.uniform(low=0.0, high=1.0, size=ncolors)\n",
    "    s = prng.uniform(low=0.4, high=0.9, size=ncolors)\n",
    "    v = prng.uniform(low=0.7, high=1.0, size=ncolors)\n",
    "    hsv = np.dstack((h, s, v))\n",
    "    rgb = np.squeeze(colors.hsv_to_rgb(hsv))\n",
    "\n",
    "    return colors.ListedColormap(rgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def generate_grid(lut):\n",
    "    \"\"\"\n",
    "    generate the grid of the lookup table from the lookup table data\n",
    "    \n",
    "    input: lookup table, numpy array\n",
    "    output: grid as numpy array, the same size as the input \n",
    "    \"\"\"\n",
    "    \n",
    "    lut_grid = np.zeros(lut.shape)\n",
    "    pix_x, pix_y = lut_grid.shape\n",
    "\n",
    "    for i in range(pix_x-1):\n",
    "        for j in range(pix_y-1):\n",
    "            if lut[i,j] != lut[i+1,j]:\n",
    "                lut_grid[i,j] = 1\n",
    "                lut_grid[i+1,j] = 1\n",
    "            if lut[i,j] != lut[i,j+1]:\n",
    "                lut_grid[i,j] = 1\n",
    "                lut_grid[i,j+1] = 1\n",
    "    \n",
    "    return lut_grid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  \n",
    "#### 8.1 pixel discrimination using ANN algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  \n",
    "### Conclusion - accuracy using all channel data as input\n",
    "***\n",
    "* Decision Tree: 0.667570 (max_depth=21) \n",
    "* Naive Bayes (GaussianNB): 0.445725  \n",
    "* Naive Bayes (BernoulliNB): 0.124037  \n",
    "* Naive Bayes (MultinomialNB): 0.649577  \n",
    "* Naive Bayes (ComplementNB): 0.146607  \n",
    "* KNN: 0.783 (500k training, 7 neighbors)\n",
    "* Random Forest: 0.763 (estimator=120, criterion='gini', min_samples_split=20, fall training and testing)\n",
    "* SVM: 0.691 (50k training, 4000 testing)  \n",
    "  \n",
    "  <b>The KNN and Random Forest achieved best results, however, KNN is slow on prediction, and RF is slow on fitting and require large amount of memory. SVM is extream slow in fitting, however, with smaller amount of training data, it could achieve good result. Decision Tree yield resonable results with reasonable fitting time. Naive Bayes gives the worst results.</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  \n",
    "## Continued in [Part 2-4](https://github.com/yzhang3000/Machine-Learning-Techniques-on-PET-block-detector-development/blob/master/python/PET_detector_block_02-.md)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
